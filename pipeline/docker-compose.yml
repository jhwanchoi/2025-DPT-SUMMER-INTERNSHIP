version: '3.8'

services:
  # PostgreSQL 데이터베이스 (Day 2에서 사용)
  postgres:
    image: postgres:15
    container_name: kpi_postgres
    environment:
      POSTGRES_USER: kpi_user
      POSTGRES_PASSWORD: kpi_password
      POSTGRES_DB: kpi_db
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./data/init.sql:/docker-entrypoint-initdb.d/init.sql
    networks:
      - kpi_network

  fastapi:
    build:
      context: ./app
    container_name: kpi_fastapi
    depends_on:
      - postgres
    working_dir: /app
    environment:
      DATABASE_URL: postgresql://kpi_user:kpi_password@postgres:5432/kpi_db
      PYTHONPATH: /app
    ports:
      - "8000:8000"
    volumes:
      - ./app:/app
    command: uvicorn main:app --host 0.0.0.0 --port 8000 --reload
    networks:
      - kpi_network

  client:
    build: ../cproject/dajeong/client
    container_name: kpi_client
    depends_on:
      - fastapi
    stdin_open: true
    tty: true
    networks:
      - kpi_network

  # Redis (Airflow용 - Day 3에서 사용)
  # redis:
  #   image: redis:7
  #   container_name: kpi_redis
  #   ports:
  #     - "6379:6379"
  #   networks:
  #     - kpi_network

  # # Airflow Webserver (Day 3에서 사용)
  # airflow-webserver:
  #   image: apache/airflow:2.7.3
  #   container_name: kpi_airflow_webserver
  #   depends_on:
  #     - postgres
  #     - redis
  #   environment:
  #     AIRFLOW__CORE__EXECUTOR: CeleryExecutor
  #     AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://kpi_user:kpi_password@postgres/kpi_db
  #     AIRFLOW__CELERY__RESULT_BACKEND: db+postgresql://kpi_user:kpi_password@postgres/kpi_db
  #     AIRFLOW__CELERY__BROKER_URL: redis://:@redis:6379/0
  #     AIRFLOW__CORE__FERNET_KEY: ''
  #     AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: 'true'
  #     AIRFLOW__CORE__LOAD_EXAMPLES: 'false'
  #     AIRFLOW__API__AUTH_BACKENDS: 'airflow.api.auth.backend.basic_auth'
  #     _PIP_ADDITIONAL_REQUIREMENTS: ''
  #   volumes:
  #     - ./airflow/dags:/opt/airflow/dags
  #     - ./airflow/logs:/opt/airflow/logs
  #     - ./airflow/plugins:/opt/airflow/plugins
  #     - ./airflow/scripts:/opt/airflow/scripts
  #   ports:
  #     - "8080:8080"
  #   command: webserver
  #   networks:
  #     - kpi_network

  # # Airflow Scheduler (Day 3에서 사용)
  # airflow-scheduler:
  #   image: apache/airflow:2.7.3
  #   container_name: kpi_airflow_scheduler
  #   depends_on:
  #     - postgres
  #     - redis
  #   environment:
  #     AIRFLOW__CORE__EXECUTOR: CeleryExecutor
  #     AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://kpi_user:kpi_password@postgres/kpi_db
  #     AIRFLOW__CELERY__RESULT_BACKEND: db+postgresql://kpi_user:kpi_password@postgres/kpi_db
  #     AIRFLOW__CELERY__BROKER_URL: redis://:@redis:6379/0
  #     AIRFLOW__CORE__FERNET_KEY: ''
  #     AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: 'true'
  #     AIRFLOW__CORE__LOAD_EXAMPLES: 'false'
  #     _PIP_ADDITIONAL_REQUIREMENTS: ''
  #   volumes:
  #     - ./airflow/dags:/opt/airflow/dags
  #     - ./airflow/logs:/opt/airflow/logs
  #     - ./airflow/plugins:/opt/airflow/plugins
  #     - ./airflow/scripts:/opt/airflow/scripts
  #   command: scheduler
  #   networks:
  #     - kpi_network

volumes:
  postgres_data:

networks:
  kpi_network:
    driver: bridge 